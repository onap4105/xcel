#!/usr/bin/env python3

# ----------------------------------------------------------
# Copyright (c) 2025 AT&T Inc. All Rights Reserved.
# ----------------------------------------------------------

"""
Copyright Header Updater v1.0

KEY FEATURES:
===================================================
1. MULTI-LANGUAGE SUPPORT:
   - 12+ languages (Python, C/C++, Java, Shell, etc.)
   - Custom comment formats (prefix/suffix)
   - Special cases (HTML/Markdown comments)

2. INTELLIGENT FILE DETECTION:
   - Shbang (#!) parsing with version support
   - File extension fallback
   - Sorted pattern matching (longest-first)

3. SAFE OPERATION MODES:
   - Dry-run preview
   - Atomic writes with permission preservation
   - Configurable exclusions (build/, .git/, etc.)

4. ENHANCED LOGGING:
   - Timestamped main log
   - Separate unsupported files log (-s flag)
   - Processing statistics

5. FLEXIBLE CONFIGURATION:
   - YAML-based config
   - Per-language settings:
     * Comment styles
     * File extensions
     * Shbang patterns
   - Global copyright text

6. ERROR HANDLING:
   - Graceful skip for:
     * Binary files
     * Unsupported types
     * Permission issues
   - Detailed error logging

USAGE:
===================================================
Basic:      ./copyright_updater [DIRECTORY] [dryrun|update]
With logs:  ./copyright_updater [DIRECTORY] update -s

CONFIGURATION:
===================================================
Edit config.yaml to:
- Add new languages
- Modify comment formats
- Update file associations
- Adjust excluded directories

Dependencies:
  - Python 3.8+

"""

import os
import re
import argparse
import subprocess
import tempfile
import sys
from typing import Dict, Any, Optional, List, Tuple
import yaml
import logging
from pathlib import Path
from datetime import datetime

# Check if the Python version is at least 3.8
assert sys.version_info >= (3, 8), "Python 3.8 or higher is required."

def setup_logging(config_dir: Path, unsupported_log: bool = False) -> None:
    """Configure logging with timestamped filenames."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    main_log = config_dir / f'copyright_updater_{timestamp}.log'

    logging.basicConfig(
        filename=str(main_log),
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # Clear any existing handlers
    logging.getLogger().handlers.clear()

    # Main file handler
    file_handler = logging.FileHandler(str(main_log))
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    logging.getLogger().addHandler(file_handler)

    # Console handler
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    logging.getLogger().addHandler(console)

    # Unsupported files logger (separate instance)
    unsupported_logger = logging.getLogger('unsupported')
    unsupported_logger.propagate = False

    if unsupported_log:
        unsupported_logfile = config_dir / f'unsupported_files_{timestamp}.log'
        unsupported_handler = logging.FileHandler(str(unsupported_logfile))
        unsupported_handler.setLevel(logging.WARNING)
        unsupported_handler.setFormatter(logging.Formatter('%(message)s'))
        unsupported_logger.addHandler(unsupported_handler)

    logging.info("Main log file: %s", main_log)
    if unsupported_log:
        logging.info("Unsupported files log: %s", unsupported_logfile)

def load_config() -> Tuple[Dict[str, Any], Dict[str, str], List[Tuple[str, str]]]:
    """Load and validate configuration from copyright_config.yaml."""
    config_path = Path(__file__).parent / "copyright_config.yaml"

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError as ex:
        logging.error("Configuration file not found at %s", config_path)
        sys.exit(1)
    except yaml.YAMLError as ex:
        logging.error("Error parsing copyright_config.yaml: %s", ex)
        sys.exit(1)

    required_keys = {'languages', 'exclude_dirs', 'copyright_text'}
    missing_keys = required_keys - set(config.keys())
    if missing_keys:
        logging.error("Missing required configuration keys: %s", ", ".join(missing_keys))
        sys.exit(1)

    # Build extension to language mapping
    ext_to_lang = {}
    for lang, settings in config['languages'].items():
        for ext in settings.get('extensions', []):
            ext_to_lang[ext] = lang

    # Build sorted shbang patterns (longest first)
    shbang_patterns = []
    for lang, settings in config['languages'].items():
        for pattern in settings.get('shbang_patterns', []):
            shbang_patterns.append((lang, pattern))

    shbang_patterns.sort(key=lambda x: (-len(x[1]), x[1]))

    return config, ext_to_lang, shbang_patterns

def generate_header(language: str, config: Dict[str, Any]) -> Optional[str]:
    """Generate copyright header for a given language."""
    lang_config = config['languages'].get(language)
    if not lang_config:
        return None

    prefix = lang_config.get('prefix', '')
    suffix = lang_config.get('suffix', '')
    copyright_text = config['copyright_text']

    copyright_line = f"{prefix}{copyright_text}{suffix}".strip()
    line_length = max(len(copyright_line), 60)
    decorative_line = f"{prefix}{'-' * (line_length - len(prefix) - len(suffix))}{suffix}"

    return f"{decorative_line}\n{copyright_line}\n{decorative_line}\n\n"

def extract_shbang_components(shbang_line: str) -> List[str]:
    """Extract all possible language components from a shbang line."""
    parts = shbang_line[2:].strip().split()
    if not parts:
        return []

    interpreter = parts[0]
    components = []

    # 1. Full interpreter name
    components.append(os.path.basename(interpreter))

    # 2. Split version numbers
    if '.' in components[-1]:
        base = components[-1].split('.')[0]
        components.append(base)
        if base[-1].isdigit():
            components.append(base.rstrip('0123456789'))

    # 3. env-style patterns
    if len(parts) > 1 and parts[0].endswith('/env'):
        components.extend(parts[1:])

    # Clean and deduplicate
    clean_components = []
    for component in components:
        clean = re.sub(r'[^a-zA-Z0-9]', '', component.lower())
        if clean:
            clean_components.append(clean)

    return list(set(clean_components))

def get_language(file_path: Path, ext_to_lang: Dict[str, str],
                shbang_patterns: List[Tuple[str, str]]) -> Optional[str]:
    """Determine language from shbang line or extension."""
    # First check shbang line
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            if first_line.startswith('#!'):
                components = extract_shbang_components(first_line)

                for lang, pattern in shbang_patterns:
                    clean_pattern = re.sub(r'[^a-zA-Z0-9]', '', pattern.lower())
                    if clean_pattern in components:
                        return lang

                unsupported_logger = logging.getLogger('unsupported')
                unsupported_logger.warning(f"Unrecognized shbang: {first_line} in {file_path}")

    except Exception as ex:
        unsupported_logger = logging.getLogger('unsupported')
        unsupported_logger.warning(f"{file_path} - Read error: {ex}")
        return None

    # Fall back to extension
    ext = file_path.suffix[1:].lower()
    return ext_to_lang.get(ext)

def check_existing_copyright(content: str, config: Dict[str, Any]) -> bool:
    """Check if copyright text exists in the first 30 lines."""
    copyright_text = config['copyright_text']
    lines = content.split('\n')[:30]
    return any(copyright_text in line for line in lines)

def is_text_file(file_path: Path) -> bool:
    """Check if a file is a text file using the 'file' command."""
    try:
        result = subprocess.run(
            ['file', '--mime-type', '-b', str(file_path)],
            capture_output=True, text=True, check=True
        )
        is_text = result.stdout.strip().startswith('text/')
        if not is_text:
            unsupported_logger = logging.getLogger('unsupported')
            unsupported_logger.warning(f"{file_path} - SKIPPED - Non-text file")
        return is_text
    except subprocess.CalledProcessError as ex:
        unsupported_logger = logging.getLogger('unsupported')
        unsupported_logger.warning(f"{file_path} - File type detection failed: {ex}")
        return False

def main() -> None:
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(description='Add copyright headers to files.')
    parser.add_argument('directory', type=str, help='Directory to process')
    parser.add_argument('run_mode', nargs='?', default='dryrun',
                      choices=['dryrun', 'update'],
                      help="Run mode: 'dryrun' or 'update'")
    parser.add_argument("-s", "--unsupported-log", 
                      action='store_true',
                      help="Create separate log for unsupported files")
    args = parser.parse_args()

    config_dir = Path(__file__).parent
    setup_logging(config_dir, args.unsupported_log)
    logging.info("=== Copyright Header Update Process Started ===")
    
    config, ext_to_lang, shbang_patterns = load_config()
    root_dir = Path(args.directory)
    dry_run = args.run_mode.lower() != 'update'

    if not root_dir.is_dir():
        logging.error("Invalid directory: %s", root_dir)
        sys.exit(1)

    # Process and normalize excluded directories
    excluded_dirs = set()
    for dir_path in config['exclude_dirs']:
        # Normalize path format: strip slashes, standardize separators
        normalized = dir_path.strip('/').replace(os.path.sep, '/')
        excluded_dirs.add(normalized)

    stats = {'processed': 0, 'updated': 0, 'passed': 0, 'errors': 0}
    
    for root, dirs, files in os.walk(root_dir):
        # Get relative path from root directory
        current_rel_path = os.path.relpath(root, root_dir)
        if current_rel_path == '.':
            current_rel_path = ''
        else:
            current_rel_path = current_rel_path.replace(os.path.sep, '/')

        # Check if current directory is excluded
        if current_rel_path in excluded_dirs:
            dirs[:] = []  # Prune all subdirectories
            continue

        # Filter subdirectories for exclusion
        new_dirs = []
        for dir_name in dirs:
            subdir_rel_path = f"{current_rel_path}/{dir_name}" if current_rel_path else dir_name
            
            if subdir_rel_path in excluded_dirs:
                logging.debug("Skipping excluded directory: %s", subdir_rel_path)
                continue
                
            new_dirs.append(dir_name)
        dirs[:] = new_dirs  # Modify in-place to control traversal

        # Process files in current directory
        for file in files:
            file_path = Path(root) / file
            stats['processed'] += 1
            
            try:
                if not is_text_file(file_path):
                    logging.info("%s - SKIPPED - Non-text file", file_path)
                    continue

                language = get_language(file_path, ext_to_lang, shbang_patterns)
                if not language:
                    logging.info("%s - SKIPPED - Unsupported type", file_path)
                    continue

                header = generate_header(language, config)
                if not header:
                    logging.info("%s - SKIPPED - No header format", file_path)
                    continue

                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                if check_existing_copyright(content, config):
                    logging.info("%s - PASSED - Copyright Existing", file_path)
                    stats['passed'] += 1
                    continue

                shbang_line, rest_content = parse_shbang(content)
                
                if dry_run:
                    logging.info("%s - DRY_RUN - Copyright Missing", file_path)
                else:
                    update_file(file_path, header, shbang_line, rest_content)
                    logging.info("%s - UPDATED", file_path)
                    stats['updated'] += 1

            except Exception as ex:
                stats['errors'] += 1
                logging.error("%s - ERROR - %s", file_path, ex)

    logging.info("\n=== Processing Summary ===")
    logging.info("Total files processed: %d", stats['processed'])
    logging.info("Files updated:         %d", stats['updated'])
    logging.info("Files passed:          %d", stats['passed'])
    logging.info("Files with errors:     %d", stats['errors'])
    logging.info("=== Process Completed ===")

def parse_shbang(content: str) -> Tuple[Optional[str], str]:
    """Extract shbang line if present."""
    if content.startswith('#!'):
        lines = content.split('\n', 1)
        return lines[0], lines[1] if len(lines) > 1 else ''
    return None, content

def update_file(file_path: Path, header: str, shbang_line: Optional[str], rest_content: str) -> None:
    """Perform atomic file update with permission preservation."""
    original_mode = file_path.stat().st_mode
    with tempfile.NamedTemporaryFile(
        mode='w',
        delete=False,
        encoding='utf-8',
        dir=str(file_path.parent)
    ) as tmp_file:
        if shbang_line:
            tmp_file.write(f"{shbang_line}\n\n")
        tmp_file.write(header)
        tmp_file.write(rest_content)

    tmp_path = Path(tmp_file.name)
    tmp_path.chmod(original_mode)
    tmp_path.replace(file_path)

if __name__ == '__main__':
    main()
